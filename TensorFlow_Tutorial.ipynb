{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7f2ZIdF6L4IBOGlrBvenW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushikpr/Machine-Learning-Prerequisites/blob/TensorFlow-Tutorial/TensorFlow_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xn4-I0LekHLK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TensorFlow Basics**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AITnQH1BZgDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors are n dimensional array representation"
      ],
      "metadata": {
        "id": "-Kkq_oLAOoL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant([[1., 2., 3.],\n",
        "                 [4., 5., 6.]])\n",
        "print(x)\n",
        "#shape of the tensor\n",
        "print(x.shape)\n",
        "#data type it holds\n",
        "print(x.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdVX64ixZhq5",
        "outputId": "01697bef-0b83-4691-f7a0-8f04fc1ec4fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
            "(2, 3)\n",
            "<dtype: 'float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Operations on tensor"
      ],
      "metadata": {
        "id": "SdXSZBP6POfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.constant([[1., 4., 9.],\n",
        "                 [40., 5., 66.]])\n",
        "# adding \n",
        "print(x+y)\n",
        "#Scaling\n",
        "print(5*x)\n",
        "#Transpose\n",
        "print(tf.transpose(x))\n",
        "#concatenate\n",
        "print(tf.concat([x,y],axis=0))#tf.concat([tf1,....tfn],axis=upto dimension-1) \n",
        "#convert to pdf\n",
        "print(tf.nn.softmax(x,axis=-1))\n",
        "#sum everything up\n",
        "print(tf.reduce_sum(x))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWf0ZNgLOhhI",
        "outputId": "01a4b123-c40c-4189-d290-d3a2a60bb7ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 2.  6. 12.]\n",
            " [44. 10. 72.]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 5. 10. 15.]\n",
            " [20. 25. 30.]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 4.]\n",
            " [2. 5.]\n",
            " [3. 6.]], shape=(3, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.  2.  3.]\n",
            " [ 4.  5.  6.]\n",
            " [ 1.  4.  9.]\n",
            " [40.  5. 66.]], shape=(4, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.09003057 0.24472848 0.66524094]\n",
            " [0.09003057 0.24472848 0.66524094]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(21.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Utilizing the GPU for optimized working"
      ],
      "metadata": {
        "id": "Z6Ss3-NOSTDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.config.list_physical_devices('GPU'):\n",
        "  print('YES')\n",
        "else:\n",
        "    print(\"NO\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHsAeV0lSYPs",
        "outputId": "ee050016-36e3-4547-adaa-968c36a240f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Creating mutable Variables"
      ],
      "metadata": {
        "id": "2dtE15LuUg-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var = tf.Variable([1,2,3])\n",
        "print(var)\n",
        "new = var\n",
        "new.assign([4,5,6])\n",
        "print(new)\n",
        "#adding/subtracting to the previous values\n",
        "print(var.assign_add([10,20,30]))\n",
        "print(var.assign_sub([1,1,1]))\n",
        "#converting to numpy\n",
        "print(var.numpy())\n",
        "#converting to tensor\n",
        "print(tf.convert_to_tensor(var))\n",
        "#highest index\n",
        "print(tf.argmax(var))\n",
        "#reshaping\n",
        "print(tf.reshape(var,[3,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6yL6-bgU1TM",
        "outputId": "eede1ceb-b14c-46c1-a060-c72d8a7d1775"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([1, 2, 3], dtype=int32)>\n",
            "<tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([4, 5, 6], dtype=int32)>\n",
            "<tf.Variable 'UnreadVariable' shape=(3,) dtype=int32, numpy=array([14, 25, 36], dtype=int32)>\n",
            "<tf.Variable 'UnreadVariable' shape=(3,) dtype=int32, numpy=array([13, 24, 35], dtype=int32)>\n",
            "[13 24 35]\n",
            "tf.Tensor([13 24 35], shape=(3,), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[13]\n",
            " [24]\n",
            " [35]], shape=(3, 1), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Multiplying tensors in matrice format VS elementwise"
      ],
      "metadata": {
        "id": "MgoZFb2ZXqCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])#matrice of 2x3\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])#matrice of 3x2\n",
        "c = tf.matmul(a, b)\n",
        "print(c.numpy()) # matrice of 2x2\n",
        "x=tf.reshape(b,[2,3]) # matching vector b(3x2) to vector a(2x3)\n",
        "print(a*x)#multiplying elements of respective indexes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI3wFO6cZ1F0",
        "outputId": "a2b9dca6-952d-4a27-a599-07bb04b94d08"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[22. 28.]\n",
            " [49. 64.]]\n",
            "tf.Tensor(\n",
            "[[ 1.  4.  9.]\n",
            " [16. 25. 36.]], shape=(2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Automated Differentiation**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7rUmVkbElEs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(3.0)\n",
        "with tf.GradientTape() as tape:\n",
        "  y = x**2\n",
        "\n",
        "dy = tape.gradient(y,x)\n",
        "print(dy)\n",
        "\n",
        "w = tf.Variable(tf.random.normal((3,2)))\n",
        "print(w)\n",
        "b = tf.Variable(tf.zeros(2,dtype=tf.float32))\n",
        "print(b)\n",
        "x= [[1,2,3]]\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  y = x@w+b\n",
        "  loss = tf.reduce_mean(y**2)\n",
        "\n",
        "[dlw,dlb] = tape.gradient(loss,[w,b])\n",
        "print(dlw,dlb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUdaFliWlEXl",
        "outputId": "eb23c531-dd96-4a31-9f49-0e7af980152d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n",
            "<tf.Variable 'Variable:0' shape=(3, 2) dtype=float32, numpy=\n",
            "array([[-1.8109758 , -1.6473049 ],\n",
            "       [-0.44288102, -0.4863753 ],\n",
            "       [-0.18886766,  0.3907121 ]], dtype=float32)>\n",
            "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>\n",
            "tf.Tensor(\n",
            "[[-3.2633407 -1.4479191]\n",
            " [-6.5266814 -2.8958383]\n",
            " [-9.790022  -4.3437576]], shape=(3, 2), dtype=float32) tf.Tensor([-3.2633407 -1.4479191], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding Graphs in Tensors**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZwLnqC7o2dct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to process data till now, we require a python intepreter interface, But if we want to utilize this data without the intepreter or export it in a form of readable datasheet(ex:*.csv files) We can convert .Tensor variables to datasheets with the help of tf.Graph( In tensorflow Graphs are data structures)\n",
        "To Create Graphs in Tensors We have a few steps"
      ],
      "metadata": {
        "id": "R3SWs62KtfJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Setup"
      ],
      "metadata": {
        "id": "Y0uABqf1srYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import datetime as dt\n",
        "import timeit"
      ],
      "metadata": {
        "id": "z75BD1S9sugt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Creating a tf.function to generates a graph"
      ],
      "metadata": {
        "id": "FwLYvqxutAFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Python function performing a function xy+b\n",
        "def basefunc(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "\n",
        "# Make some tensors.\n",
        "x1 = tf.constant([[1.0, 2.0]])\n",
        "y1 = tf.constant([[2.0], [3.0]])\n",
        "b1 = tf.constant(4.0)\n",
        "\n",
        "#Creating a variable using tf.function that performs the function and generates a graph\n",
        "a_function_that_uses_a_graph = tf.function(basefunc)\n",
        "\n",
        "\n",
        "#Calling the function directly \n",
        "fwog = basefunc(x1, y1, b1).numpy()\n",
        "# Calling the function created by tf.function\n",
        "fwg = a_function_that_uses_a_graph(x1, y1, b1)\n",
        "\n",
        "#Both perform the sae function yet one contains the graph and one doesnt\n",
        "print(fwg==fwog)\n",
        "\n",
        "#Creating a tf.function using decorator\n",
        "@tf.function\n",
        "def tensfunc(x):\n",
        "  y = tf.constant([[2.0], [3.0]])\n",
        "  b = tf.constant(4.0)\n",
        "\n",
        "  return basefunc(x,y,b)\n",
        "\n",
        "#Calling using decorator generates a graph for both basefunc and tensfunc\n",
        "tensfunc(tf.constant([[1.0, 2.0]])).numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLXnoyFP2geX",
        "outputId": "79635bf8-c139-41d2-89da-aa60a6c169b5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ True]], shape=(1, 1), dtype=bool)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Converting tf.functions to graphs"
      ],
      "metadata": {
        "id": "uJ3ZiA1OzEeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensfunc.get_concrete_function(x1).graph.as_graph_def()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70_Qw5JpzMZ3",
        "outputId": "589a30e7-cbc7-43d8-e0b3-b6ea928653de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "node {\n",
              "  name: \"x\"\n",
              "  op: \"Placeholder\"\n",
              "  attr {\n",
              "    key: \"_user_specified_name\"\n",
              "    value {\n",
              "      s: \"x\"\n",
              "    }\n",
              "  }\n",
              "  attr {\n",
              "    key: \"dtype\"\n",
              "    value {\n",
              "      type: DT_FLOAT\n",
              "    }\n",
              "  }\n",
              "  attr {\n",
              "    key: \"shape\"\n",
              "    value {\n",
              "      shape {\n",
              "        dim {\n",
              "          size: 1\n",
              "        }\n",
              "        dim {\n",
              "          size: 2\n",
              "        }\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}\n",
              "node {\n",
              "  name: \"Const\"\n",
              "  op: \"Const\"\n",
              "  attr {\n",
              "    key: \"dtype\"\n",
              "    value {\n",
              "      type: DT_FLOAT\n",
              "    }\n",
              "  }\n",
              "  attr {\n",
              "    key: \"value\"\n",
              "    value {\n",
              "      tensor {\n",
              "        dtype: DT_FLOAT\n",
              "        tensor_shape {\n",
              "          dim {\n",
              "            size: 2\n",
              "          }\n",
              "          dim {\n",
              "            size: 1\n",
              "          }\n",
              "        }\n",
              "        tensor_content: \"\\000\\000\\000@\\000\\000@@\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}\n",
              "node {\n",
              "  name: \"Const_1\"\n",
              "  op: \"Const\"\n",
              "  attr {\n",
              "    key: \"dtype\"\n",
              "    value {\n",
              "      type: DT_FLOAT\n",
              "    }\n",
              "  }\n",
              "  attr {\n",
              "    key: \"value\"\n",
              "    value {\n",
              "      tensor {\n",
              "        dtype: DT_FLOAT\n",
              "        tensor_shape {\n",
              "        }\n",
              "        float_val: 4.0\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}\n",
              "node {\n",
              "  name: \"MatMul\"\n",
              "  op: \"MatMul\"\n",
              "  input: \"x\"\n",
              "  input: \"Const\"\n",
              "  attr {\n",
              "    key: \"T\"\n",
              "    value {\n",
              "      type: DT_FLOAT\n",
              "    }\n",
              "  }\n",
              "  attr {\n",
              "    key: \"transpose_a\"\n",
              "    value {\n",
              "      b: false\n",
              "    }\n",
              "  }\n",
              "  attr {\n",
              "    key: \"transpose_b\"\n",
              "    value {\n",
              "      b: false\n",
              "    }\n",
              "  }\n",
              "}\n",
              "node {\n",
              "  name: \"add\"\n",
              "  op: \"AddV2\"\n",
              "  input: \"MatMul\"\n",
              "  input: \"Const_1\"\n",
              "  attr {\n",
              "    key: \"T\"\n",
              "    value {\n",
              "      type: DT_FLOAT\n",
              "    }\n",
              "  }\n",
              "}\n",
              "node {\n",
              "  name: \"Identity\"\n",
              "  op: \"Identity\"\n",
              "  input: \"add\"\n",
              "  attr {\n",
              "    key: \"T\"\n",
              "    value {\n",
              "      type: DT_FLOAT\n",
              "    }\n",
              "  }\n",
              "}\n",
              "versions {\n",
              "  producer: 987\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tf.Functions**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5T4dVTcs16yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Polymorphism :\n",
        "tf.function can generate many graphs depeending on the input signature(data types)"
      ],
      "metadata": {
        "id": "LYvRon724foU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensfunc(tf.constant([[1.0, 2.0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdPPygWh4tXN",
        "outputId": "cc4e9494-b719-459d-9844-84a0983e68be"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[12.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Eagerly vs graphically: tf.functions can be set to run without generating graph(eagerly) "
      ],
      "metadata": {
        "id": "mGQqD7xc5551"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#running eagerly settings\n",
        "tf.config.run_functions_eagerly(True)\n",
        "#running graphically settings\n",
        "tf.config.run_functions_eagerly(False)\n",
        "# graphically takes a lot of load"
      ],
      "metadata": {
        "id": "m3JPZ7nG59-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Practise of tf.function\n",
        "\n",
        "1. It may take some time to get used to the behavior of Function. To get started quickly, first-time users should play around with decorating toy functions with @tf.function to get experience with going from eager to graph execution.\n",
        "2. Toggle between eager and graph execution early and often with tf.config.run_functions_eagerly to pinpoint if/ when the two modes diverge.\n",
        "3. Create tf.Variables outside the Python function and modify them on the inside. The same goes for objects that use tf.Variable, like keras.layers, keras.Models and tf.optimizers.\n",
        "4. Avoid writing functions that depend on outer Python variables, excluding tf.Variables and Keras objects. \n",
        "5. Prefer to write functions which take tensors and other TensorFlow types as input.\n",
        "6. You can pass in other object types but be careful! Include as much computation as possible under a tf.function to maximize the performance gain. For example, decorate a whole training step or the entire training loop.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z2DonIPc_q3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Timing of Graph Functions vs Eager Function"
      ],
      "metadata": {
        "id": "PkhpU5tDAnDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using Graphs\n",
        "tf.config.run_functions_eagerly(False)\n",
        "print('Graphs:',timeit.timeit(lambda: tensfunc(tf.constant([[1.0, 2.0]])),number=1000))\n",
        "#Using Eager\n",
        "tf.config.run_functions_eagerly(True)\n",
        "print('Eager:',timeit.timeit(lambda: tensfunc(tf.constant([[1.0, 2.0]])),number=1000))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weTebRt_AtN-",
        "outputId": "77ee66ed-2f44-41da-a892-9608d5d8454d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graphs: 0.7734685890000037\n",
            "Eager: 0.24355980699965585\n"
          ]
        }
      ]
    }
  ]
}